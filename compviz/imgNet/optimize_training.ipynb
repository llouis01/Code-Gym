{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Env Set Up #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import gc as G\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K, mixed_precision\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras_tuner as kt\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau as RLOP, ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier as KC\n",
    "from sklearn.model_selection import RandomizedSearchCV as RSCV\n",
    "from utils import import_train, import_others, view_train_images, plot_training_results\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPU memory limit (3GB out of 4GB)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3072)]  # 3GB = 3072MB\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Data Import #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths for data\n",
    "train_dir = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/train\"\n",
    "val_dir = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/val\"\n",
    "test_dir = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/test\"\n",
    "\n",
    "# path to save tuner results\n",
    "kt_path = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/tuning_res/kt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images processed: 12500 (25%)\n",
      "Images processed: 25000 (50%)\n",
      "Images processed: 37500 (75%)\n",
      "Function processed C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/train in 283 seconds.\n",
      "\n",
      "Images processed: 2500 (25%)\n",
      "Images processed: 5000 (50%)\n",
      "Images processed: 7500 (75%)\n",
      "Function processed C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/val in 92 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data import\n",
    "train_images, train_labels = import_train(train_dir, 50000)\n",
    "test_images, test_labels = import_train(val_dir, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "X_train = np.array(train_images)\n",
    "X_train = np.repeat(X_train, 3, -1)\n",
    "\n",
    "Y_train = [str(s) for s in train_labels]\n",
    "label_encoder = LabelEncoder()\n",
    "Y_train = label_encoder.fit_transform(Y_train)\n",
    "Y_hot = to_categorical(Y_train, num_classes=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare testing data\n",
    "X_test = np.array(test_images)\n",
    "X_test = np.repeat(X_test, 3, -1)\n",
    "\n",
    "Y_test = [str(s) for s in test_labels]\n",
    "label_encoder = LabelEncoder()\n",
    "Y_test = label_encoder.fit_transform(Y_test)\n",
    "Y_test_hot = to_categorical(Y_test, num_classes=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "(10000,)\n",
      "1000\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# check data shape\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "print(len(np.unique(Y_train)))\n",
    "print(len(np.unique(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Model Optimization #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Keras Classifier ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for tuning\n",
    "epx = 50\n",
    "batch_size = 8\n",
    "RSCV_opts = ['adam', 'rmsprop']\n",
    "krnl = (3, 3)\n",
    "in_shape = (64, 64, 3)\n",
    "RSCV_activation = ['relu', 'tanh', 'sigmoid']\n",
    "RSCV_node1 = [2, 4, 8, 16, 32]\n",
    "RSCV_node2 = [2, 4, 8, 16, 32]\n",
    "RSCV_drop = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "RSCV_bacth = [2, 4, 6, 8, 16, 32, 64, 128]\n",
    "\n",
    "params_grid = dict(node1 = RSCV_node1,\n",
    "               node2 = RSCV_node2,\n",
    "               activations = RSCV_activation,\n",
    "               optimizers = RSCV_opts,\n",
    "               batch_size = RSCV_bacth,\n",
    "               drops = RSCV_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Classifier needs a model builder function to instantiate a new model for each new grid point\n",
    "def build_CNN(optimizers, node1, activations, node2, drops):\n",
    "    CNN = Sequential([\n",
    "        # first layer\n",
    "        Conv2D(node1, kernel_size=krnl, activation=activations, input_shape=in_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        # 2nd layer\n",
    "        Conv2D(node2, kernel_size=krnl, activation=activations),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        # output layer\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(drops),\n",
    "        Dense(1000, 'softmax')\n",
    "    ])\n",
    "    CNN.compile(optimizers,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    # return built model\n",
    "    return CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RoiMinuit\\AppData\\Local\\Temp\\ipykernel_41516\\1010408690.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  RS_cnn = KC(build_fn=build_CNN,\n"
     ]
    }
   ],
   "source": [
    "# build Keras Classifier\n",
    "RS_cnn = KC(build_fn=build_CNN,\n",
    "            verbose=1,\n",
    "            epochs=5,\n",
    "            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish search space and search\n",
    "grid_search = RSCV(RS_cnn,\n",
    "                   param_distributions=params_grid,\n",
    "                   cv=5,\n",
    "                   scoring='accuracy',\n",
    "                   verbose=1)\n",
    "\n",
    "# execute search with categorical Y, not one-hotted\n",
    "grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Keras Tuner ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for tuning\n",
    "units = [2, 4, 6, 8, 10, 12, 14, 16, 32, 64, 128]\n",
    "activations = ['relu', 'linear', 'sigmoid', 'selu', 'elu']\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('ImgNet_Model.h5', monitor='val_loss', save_best_only=True, save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1e6fe03b880>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base model for kt\n",
    "def build_KT_CNN(hp):\n",
    "    with tf.device('/GPU:0'):\n",
    "        layers = [\n",
    "            # input layer\n",
    "            Conv2D(hp.Int('filters', min_value=2, max_value=128),\n",
    "                input_shape=(64, 64, 3),\n",
    "                kernel_size=(3, 3),\n",
    "                activation=hp.Choice('activation', activations)),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Dropout(hp.Float('drop_rate', 1e-4, 1e-1))\n",
    "        ]\n",
    "        \n",
    "        # hidden layer(s)\n",
    "        for l in range(hp.Int('num_layers', 1, 5)):\n",
    "            layers.append(Conv2D(hp.Int('filters', min_value=2, max_value=128),\n",
    "                                kernel_size=(3, 3),\n",
    "                                activation=hp.Choice('activation', activations)))\n",
    "            layers.append(BatchNormalization())\n",
    "            layers.append(MaxPooling2D(2, 2))\n",
    "            layers.append(Dropout(hp.Float('drop_rate', 1e-4, 1e-1)))\n",
    "        \n",
    "        # output layer\n",
    "        layers.append(GlobalAveragePooling2D())\n",
    "        layers.append(Dropout(hp.Float('drop_rate', 1e-4, 1e-1)))\n",
    "        layers.append(Dense(1000, activation=hp.Choice('activation', activations)))\n",
    "        \n",
    "        CNN = Sequential(layers)\n",
    "        lr = hp.Float('learning_rate', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-3)\n",
    "        CNN.compile(optimizer=Adam(learning_rate=lr),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    # return built model\n",
    "    return CNN\n",
    "\n",
    "build_KT_CNN(kt.HyperParameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "26                |26                |filters\n",
      "linear            |linear            |activation\n",
      "0.025642          |0.025642          |drop_rate\n",
      "2                 |2                 |num_layers\n",
      "0.00043102        |0.00043102        |learning_rate\n",
      "\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "# eastablish search space and search\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=build_KT_CNN,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=2,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=kt_path,\n",
    "    project_name='ImgNetOptimization'\n",
    ")\n",
    "\n",
    "# search\n",
    "tuner.search(X_train, Y_train, epochs=2, validation_data=(X_test, Y_test), callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"conv2d_4\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_4/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_4/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,120], [3,3,120,120].\n\nCall arguments received by layer \"conv2d_4\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 2, 2, 120), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# view optimized model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:400\u001b[0m, in \u001b[0;36mTuner.get_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the tuner's objective.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03mThe models are loaded with the weights corresponding to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    List of trained model instances sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;66;03m# Method only exists in this class for the docstring override.\u001b[39;00m\n\u001b[1;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_models\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:366\u001b[0m, in \u001b[0;36mBaseTuner.get_best_models\u001b[1;34m(self, num_models)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    365\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[1;32m--> 366\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model(trial) \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[1;32mc:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:366\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the best model(s), as determined by the objective.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mThis method is for querying the models trained during the search.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    List of trained models sorted from the best to the worst.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    365\u001b[0m best_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_best_trials(num_models)\n\u001b[1;32m--> 366\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m best_trials]\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[1;32mc:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:320\u001b[0m, in \u001b[0;36mTuner.load_model\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[1;32m--> 320\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;66;03m# Build model to create the weights.\u001b[39;00m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbuilt:\n",
      "File \u001b[1;32mc:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:164\u001b[0m, in \u001b[0;36mTuner._try_build\u001b[1;34m(self, hp)\u001b[0m\n\u001b[0;32m    161\u001b[0m keras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[0;32m    162\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m--> 164\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_hypermodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# Stop if `build()` does not return a valid model.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel):\n",
      "File \u001b[1;32mc:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:155\u001b[0m, in \u001b[0;36mTuner._build_hypermodel\u001b[1;34m(self, hp)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_build_hypermodel\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp):\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m maybe_distribute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution_strategy):\n\u001b[1;32m--> 155\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_override_compile_args(model)\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "Cell \u001b[1;32mIn[11], line 29\u001b[0m, in \u001b[0;36mbuild_KT_CNN\u001b[1;34m(hp)\u001b[0m\n\u001b[0;32m     26\u001b[0m layers\u001b[38;5;241m.\u001b[39mappend(Dropout(hp\u001b[38;5;241m.\u001b[39mFloat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1e-1\u001b[39m)))\n\u001b[0;32m     27\u001b[0m layers\u001b[38;5;241m.\u001b[39mappend(Dense(\u001b[38;5;241m1000\u001b[39m, activation\u001b[38;5;241m=\u001b[39mhp\u001b[38;5;241m.\u001b[39mChoice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m, activations)))\n\u001b[1;32m---> 29\u001b[0m CNN \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m lr \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mFloat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, min_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, max_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-1\u001b[39m, sampling\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOG\u001b[39m\u001b[38;5;124m'\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m     31\u001b[0m CNN\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlr),\n\u001b[0;32m     32\u001b[0m             loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     33\u001b[0m             metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1969\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1966\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[0;32m   1967\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1968\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 1969\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[0;32m   1972\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[0;32m   1973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"conv2d_4\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_4/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_4/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,120], [3,3,120,120].\n\nCall arguments received by layer \"conv2d_4\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 2, 2, 120), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# view optimized model\n",
    "model = tuner.get_best_models()[0]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in C:/Users/RoiMinuit/Desktop/data/ILSVRC/tuning_res/kt\\ImgNetOptimization\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "units: 56\n",
      "activation: relu\n",
      "num_layers: 3\n",
      "nodes: 34\n",
      "drop_rate: 0.056074816973524635\n",
      "learning_rate: 0.003601625947816291\n",
      "Score: 1.0\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "units: 6\n",
      "activation: elu\n",
      "num_layers: 2\n",
      "nodes: 103\n",
      "drop_rate: 0.034321311243740625\n",
      "learning_rate: 0.0009050440273521296\n",
      "Score: 0.00041666667675599456\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "units: 114\n",
      "activation: linear\n",
      "num_layers: 1\n",
      "nodes: 61\n",
      "drop_rate: 0.027326859907895323\n",
      "learning_rate: 0.05328040337572006\n",
      "Score: 0.0\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "units: 97\n",
      "activation: elu\n",
      "num_layers: 5\n",
      "nodes: 100\n",
      "drop_rate: 0.09236573698403451\n",
      "learning_rate: 2.1778293990354973e-05\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 232, in _build_and_fit_model\n",
      "    model = self._try_build(hp)\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 164, in _try_build\n",
      "    model = self._build_hypermodel(hp)\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 155, in _build_hypermodel\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"C:\\Users\\RoiMinuit\\AppData\\Local\\Temp\\ipykernel_22576\\2422046186.py\", line 27, in build_KT_CNN\n",
      "    CNN = Sequential(layers)\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\", line 205, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1969, in _create_c_op\n",
      "    raise ValueError(e.message)\n",
      "ValueError: Exception encountered when calling layer \"conv2d_4\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_4/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_4/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,100], [3,3,100,100].\n",
      "\n",
      "Call arguments received by layer \"conv2d_4\" (type Conv2D):\n",
      "  • inputs=tf.Tensor(shape=(None, 2, 2, 100), dtype=float32)\n",
      "\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "units: 4\n",
      "activation: elu\n",
      "num_layers: 4\n",
      "nodes: 50\n",
      "drop_rate: 0.048195411635871856\n",
      "learning_rate: 0.002929445006758115\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 232, in _build_and_fit_model\n",
      "    model = self._try_build(hp)\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 164, in _try_build\n",
      "    model = self._build_hypermodel(hp)\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 155, in _build_hypermodel\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"C:\\Users\\RoiMinuit\\AppData\\Local\\Temp\\ipykernel_22576\\2422046186.py\", line 27, in build_KT_CNN\n",
      "    CNN = Sequential(layers)\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\", line 205, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\RoiMinuit\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1969, in _create_c_op\n",
      "    raise ValueError(e.message)\n",
      "ValueError: Exception encountered when calling layer \"conv2d_4\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_4/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_4/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,50], [3,3,50,50].\n",
      "\n",
      "Call arguments received by layer \"conv2d_4\" (type Conv2D):\n",
      "  • inputs=tf.Tensor(shape=(None, 2, 2, 50), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
