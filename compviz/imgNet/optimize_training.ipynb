{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Env Set Up #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import gc as G\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from numba import cuda\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K, mixed_precision\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import keras_tuner as kt\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau as RLOP, ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier as KC\n",
    "from sklearn.model_selection import RandomizedSearchCV as RSCV\n",
    "from utils import import_train, view_train_images, plot_training_results, fast_import as FI, fast_import2 as FI2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set GPU memory limit to prevent max preallocation\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Data Import #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "train_dir = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/train\"\n",
    "val_dir = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/val\"\n",
    "test_dir = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/test\"\n",
    "\n",
    "# path to save tuner results\n",
    "kt_path = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Tuning_Res/KT\"\n",
    "\n",
    "# save best model\n",
    "model_path = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Tuning_Res/KT/Model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function processed 20000 images in 18 seconds.\n",
      "\n",
      "Function processed 4000 images in 7 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data import - 35K\n",
    "train_images, train_labels = FI2(train_dir, 20000)\n",
    "test_images, test_labels = FI2(val_dir, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "X_train = np.array(train_images)\n",
    "X_train = np.repeat(X_train, 3, -1)\n",
    "\n",
    "Y_train = [str(s) for s in train_labels]\n",
    "label_encoder = LabelEncoder()\n",
    "Y_train = label_encoder.fit_transform(Y_train)\n",
    "Y_hot = to_categorical(Y_train, num_classes=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare testing data\n",
    "X_test = np.array(test_images)\n",
    "X_test = np.repeat(X_test, 3, -1)\n",
    "\n",
    "Y_test = [str(s) for s in test_labels]\n",
    "label_encoder = LabelEncoder()\n",
    "Y_test = label_encoder.fit_transform(Y_test)\n",
    "Y_test_hot = to_categorical(Y_test, num_classes=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,)\n",
      "(4000,)\n",
      "1000\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# check data shape\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "print(len(np.unique(Y_train)))\n",
    "print(len(np.unique(Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Model Optimization #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Keras Classifier ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for tuning\n",
    "epx = 50\n",
    "batch_size = 8\n",
    "RSCV_opts = ['adam', 'rmsprop']\n",
    "krnl = (3, 3)\n",
    "in_shape = (64, 64, 3)\n",
    "RSCV_activation = ['relu', 'tanh', 'sigmoid']\n",
    "RSCV_node1 = [2, 4, 8, 16, 32]\n",
    "RSCV_node2 = [2, 4, 8, 16, 32]\n",
    "RSCV_drop = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "RSCV_bacth = [2, 4, 6, 8, 16, 32, 64, 128]\n",
    "\n",
    "params_grid = dict(node1 = RSCV_node1,\n",
    "               node2 = RSCV_node2,\n",
    "               activations = RSCV_activation,\n",
    "               optimizers = RSCV_opts,\n",
    "               batch_size = RSCV_bacth,\n",
    "               drops = RSCV_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Classifier needs a model builder function to instantiate a new model for each new grid point\n",
    "def build_CNN(optimizers, node1, activations, node2, drops):\n",
    "    CNN = Sequential([\n",
    "        # first layer\n",
    "        Conv2D(node1, kernel_size=krnl, activation=activations, input_shape=in_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        # 2nd layer\n",
    "        Conv2D(node2, kernel_size=krnl, activation=activations),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        # output layer\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(drops),\n",
    "        Dense(1000, 'softmax')\n",
    "    ])\n",
    "    CNN.compile(optimizers,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    # return built model\n",
    "    return CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build Keras Classifier\n",
    "RS_cnn = KC(build_fn=build_CNN,\n",
    "            verbose=1,\n",
    "            epochs=5,\n",
    "            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish search space and search\n",
    "grid_search = RSCV(RS_cnn,\n",
    "                   param_distributions=params_grid,\n",
    "                   cv=5,\n",
    "                   scoring='accuracy',\n",
    "                   verbose=1)\n",
    "\n",
    "# execute search with categorical Y, not one-hotted\n",
    "grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Keras Tuner ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for tuning\n",
    "activations = ['relu', 'linear', 'sigmoid', 'selu', 'elu']\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(model_path + '/ImgNet_Model.h5', monitor='val_loss', save_best_only=True, save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1db5cc9b160>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base model for kt\n",
    "def build_KT_CNN(hp):\n",
    "    layers = [\n",
    "        # input layer\n",
    "        Conv2D(hp.Int('filters', min_value=2, max_value=64),\n",
    "            input_shape=(64, 64, 3),\n",
    "            kernel_size=(3, 3),\n",
    "            activation=hp.Choice('activation', activations)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Dropout(hp.Float('drop_rate', 1e-4, 1e-1))\n",
    "    ]\n",
    "    \n",
    "    # hidden layer(s)\n",
    "    for l in range(hp.Int('num_layers', 1, 2)):\n",
    "        layers.append(Conv2D(hp.Int('filters', min_value=2, max_value=64),\n",
    "                            kernel_size=(3, 3),\n",
    "                            activation=hp.Choice('activation', activations)))\n",
    "        layers.append(BatchNormalization())\n",
    "        layers.append(MaxPooling2D(2, 2))\n",
    "        layers.append(Dropout(hp.Float('drop_rate', 1e-4, 1e-1)))\n",
    "    \n",
    "    # output layer\n",
    "    layers.append(GlobalAveragePooling2D())\n",
    "    layers.append(Dropout(hp.Float('drop_rate', 1e-4, 1e-1)))\n",
    "    layers.append(Dense(1000, activation=hp.Choice('activation', activations)))\n",
    "    \n",
    "    CNN = Sequential(layers)\n",
    "    lr = hp.Float('learning_rate', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-3)\n",
    "    CNN.compile(optimizer=Adam(learning_rate=lr),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    # return built model\n",
    "    return CNN\n",
    "\n",
    "build_KT_CNN(kt.HyperParameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "48                |48                |filters\n",
      "elu               |elu               |activation\n",
      "0.05097           |0.05097           |drop_rate\n",
      "2                 |2                 |num_layers\n",
      "0.090899          |0.090899          |learning_rate\n",
      "\n",
      "Epoch 1/5\n",
      "  4/625 [..............................] - ETA: 11s - loss: 16.7014 - accuracy: 0.0000e+00 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0054s vs `on_train_batch_end` time: 0.0076s). Check your callbacks.\n",
      "625/625 [==============================] - 10s 15ms/step - loss: 18.1555 - accuracy: 0.0012 - val_loss: 18.3153 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 18.1558 - accuracy: 0.0013 - val_loss: 18.3153 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 18.1558 - accuracy: 0.0011 - val_loss: 18.3153 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 18.1558 - accuracy: 0.0013 - val_loss: 18.3153 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# eastablish search space and search\n",
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=build_KT_CNN,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=kt_path,\n",
    "    project_name='ImgNetOptimization'\n",
    ")\n",
    "\n",
    "# search\n",
    "tuner.search(X_train, Y_train, epochs=5, validation_data=(X_test, Y_test), callbacks=[early_stop, checkpoint])\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view optimized model\n",
    "model = tuner.get_best_models()[0]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "G.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
