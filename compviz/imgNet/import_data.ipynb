{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIJfJqKO0p0z"
      },
      "source": [
        "## ** ENV Setup ** ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f9bNrWRM0p02"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'import_train' from 'utils' (c:\\Users\\RoiMinuit\\GitHub\\Code-Gym\\Code-Gym-1\\compviz\\imgNet\\utils.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, ReduceLROnPlateau \u001b[38;5;28;01mas\u001b[39;00m RLOP\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m import_train, import_others, view_train_images, plot_training_results\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'import_train' from 'utils' (c:\\Users\\RoiMinuit\\GitHub\\Code-Gym\\Code-Gym-1\\compviz\\imgNet\\utils.py)"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import random\n",
        "import gc as G\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K, mixed_precision\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau as RLOP\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from utils import import_train, import_others, view_train_images, plot_training_results\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkC5sSUipX8L",
        "outputId": "9f9493f0-787a-4294-bbf4-ac9b59a813cb"
      },
      "outputs": [],
      "source": [
        "# set up for GPU usage\n",
        "K.clear_session()\n",
        "print(tf.__version__)\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "device = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXx3t9tQpX8O",
        "outputId": "637fb0ac-c5c5-4959-d9ad-ec6ceaac2d67"
      },
      "outputs": [],
      "source": [
        "# limit usage of GPU memory\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)  # Prevents TensorFlow from allocating all memory at once\n",
        "            print(f\"Enabled memory growth for: {gpu}\")\n",
        "\n",
        "        # Set GPU device\n",
        "        device = \"/GPU:0\"\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    device = \"/CPU:0\"\n",
        "    print(\"No GPU detected, using CPU.\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# set gpu to use max memory\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.set_logical_device_configuration(\n",
        "                gpu,\n",
        "                [tf.config.LogicalDeviceConfiguration(memory_limit=4000)]  # Set in MB (e.g., 10GB)\n",
        "            )\n",
        "        print(\"Set TensorFlow to use max GPU memory.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Disable GPU - will crash kernel\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlbcvDAA0p01"
      },
      "source": [
        "## 1) Import Data Into Project ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgQo6Eih0p02"
      },
      "outputs": [],
      "source": [
        "# paths for data\n",
        "train_dir = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/train\"\n",
        "val_dir = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/val\"\n",
        "test_dir = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/test\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGptdkCf0p02",
        "outputId": "4733b2e6-df86-48c4-91db-07f5eebb7ae2"
      },
      "outputs": [],
      "source": [
        "# import images\n",
        "train_images, train_labels = import_train(train_dir, 15000)\n",
        "# test_images = import_others(test_dir, 750)\n",
        "# val_images = import_others(val_dir, 750)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzR8m4Z70p02"
      },
      "source": [
        "## 2) Inspect Images ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kvnOOWyQ0p02",
        "outputId": "ddb34342-4161-401f-a2f1-15c23d879e6c"
      },
      "outputs": [],
      "source": [
        "# view train images\n",
        "view_train_images(train_images, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ETMF6s750p02",
        "outputId": "de24e125-3f2e-4eb4-c7ab-9e2eb22e52b3"
      },
      "outputs": [],
      "source": [
        "# type of images\n",
        "for i in range(0, 5):\n",
        "    print(type(train_images[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "K0cTQOQy0p02",
        "outputId": "c20af86d-e579-41af-b8e0-5a1949dbad83"
      },
      "outputs": [],
      "source": [
        "# check the shape of images\n",
        "for i in range(0, 5):\n",
        "    print(train_images[i].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNrhcn3r0p02"
      },
      "source": [
        "## 3) Edge Detection ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-CQJZjo0p03"
      },
      "outputs": [],
      "source": [
        "# define edge detection function\n",
        "\n",
        "def edge_detection(image_arr, low_threshold = 100, high_threshold = 200):\n",
        "    \"\"\" Detect edges in an image \"\"\"\n",
        "    # remove single channel dimension\n",
        "    image_arr = image_arr.squeeze()\n",
        "    # convert to uint8\n",
        "    if image_arr.dtype != np.uint8:\n",
        "        image_arr = (image_arr * 255).astype(np.uint8)\n",
        "    # detect edges\n",
        "    edges = cv2.Canny(image_arr, low_threshold, high_threshold)\n",
        "    return edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U675WFWy0p03"
      },
      "outputs": [],
      "source": [
        "# perform edge detection on images\n",
        "train_edge_images = [edge_detection(image) for image in train_images]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stQbmxYX0p03",
        "outputId": "8e831129-3a7b-4da5-f319-da5b6a0b2698"
      },
      "outputs": [],
      "source": [
        "# view edged image\n",
        "def view_edged_image(image_arrays, image_edge, n):\n",
        "    \"\"\" View an image array \"\"\"\n",
        "    for i in range(0, n):\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(image_arrays[i], cmap='gray')\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(image_edge[i], cmap='gray')\n",
        "        plt.show()\n",
        "\n",
        "view_edged_image(train_images, train_edge_images, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id97YGzB0p03"
      },
      "source": [
        "## 4) Machine Learning ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgp2idnD0p03"
      },
      "source": [
        "### a) Prepare Data ###\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXO3VM3A0p03"
      },
      "outputs": [],
      "source": [
        "# prepare training data\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "X_train = np.array(train_images)\n",
        "X_train = np.repeat(X_train, 3, -1)\n",
        "\n",
        "Y_train = [str(s) for s in train_labels]\n",
        "label_encoder = LabelEncoder()\n",
        "Y_train = label_encoder.fit_transform(Y_train)\n",
        "Y_hot = to_categorical(Y_train, num_classes=1000)\n",
        "\n",
        "# X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "# Y_hot = tf.convert_to_tensor(Y_hot, dtype=tf.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myG6sV6R0p03"
      },
      "outputs": [],
      "source": [
        "# # prepare validation data\n",
        "# X_val = np.array(val_images)\n",
        "\n",
        "# Y_val = [str(s) for s in val_labels]\n",
        "# Y_val = LabelEncoder.fit_transform(Y_val)\n",
        "# Y_val_hot = to_categorical(Y_val, num_classes=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1AbVblM0p03"
      },
      "outputs": [],
      "source": [
        "# # prepare test data\n",
        "# X_test = np.array(test_images)\n",
        "\n",
        "# Y_test = [str(s) for s in X_test]\n",
        "# Y_test = LabelEncoder.fit_transform(Y_test)\n",
        "# Y_test_hot = to_categorical(Y_test, num_classes=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdEf8QBo0p03"
      },
      "source": [
        "### b) Train CNN Model ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29sdMtNU0p03",
        "outputId": "91e2d33c-84c1-40f0-b8f7-fa5ce3100699"
      },
      "outputs": [],
      "source": [
        "# build and compile the convolutional neural network (CNN) model - ONLY ONCE\n",
        "# K.clear_session()\n",
        "# strategy = tf.distribute.MirroredStrategy()\n",
        "# with strategy.scope():\n",
        "CNN = keras.Sequential([\n",
        "                # first convolutional layer\n",
        "                Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "                BatchNormalization(),\n",
        "                MaxPooling2D((2, 2)),\n",
        "                # second convolutional layer with 64 neurons and w/out shape\n",
        "                Conv2D(64, (3, 3), activation='relu'),\n",
        "                BatchNormalization(),\n",
        "                MaxPooling2D((2, 2)),\n",
        "                # # Flatten out the layers\n",
        "                # Flatten(),\n",
        "                # Dense layer with 64 neurons and relu activation\n",
        "                GlobalAveragePooling2D(),\n",
        "                BatchNormalization(),\n",
        "                # Dropout layer to prevent overfitting by dropping 50% of neurons\n",
        "                Dropout(0.5),\n",
        "                # Output layer with 1000 classes and softmax activation\n",
        "                Dense(200, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        # compile model with adam, categorical crossentropy, accuracy, precision, and recall\n",
        "CNN.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy', Precision(), Recall()])\n",
        "\n",
        "# print(\"Model using device: \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) GPU-build and compile the convolutional neural network (CNN) model - ONLY ONCE\n",
        "G.collect()\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "# Allow memory growth on the GPU\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "for device in physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)  \n",
        "with tf.device('/GPU:0'):\n",
        "    CNN = keras.Sequential([\n",
        "                    # first convolutional layer\n",
        "                    Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # second convolutional layer with 64 neurons and w/out shape\n",
        "                    Conv2D(128, (3, 3), activation='relu'),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # third convolutional layer with 64 neurons and w/out shape\n",
        "                    # Conv2D(32, (3, 3), activation='relu'),\n",
        "                    # BatchNormalization(),\n",
        "                    # MaxPooling2D((2, 2)),\n",
        "                    # # Flatten out the layers\n",
        "                    # Flatten(),\n",
        "                    # Dense layer with 64 neurons and relu activation\n",
        "                    GlobalAveragePooling2D(),\n",
        "                    # Dropout layer to prevent overfitting by dropping 50% of neurons\n",
        "                    Dropout(0.5),\n",
        "                    # Output layer with 1000 classes and softmax activation\n",
        "                    Dense(1000, activation='softmax')\n",
        "            ])\n",
        "\n",
        "    # compile model with adam, categorical crossentropy, accuracy, precision, and recall\n",
        "    CNN.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy', Precision(), Recall()])\n",
        "\n",
        "# train the model\n",
        "reduce_lr = RLOP(monitor='val_loss', factor=0.0001, patience=10, min_lr=0)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "hist_1 = CNN.fit(\n",
        "    X_train, Y_hot,\n",
        "    batch_size=16,\n",
        "    epochs=100,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[reduce_lr, early_stop]\n",
        ")\n",
        "\n",
        "# plot training results\n",
        "plot_training_results(hist_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "G.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy is high 69% but val_acc is very low 0.07%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veuSeMm80p03",
        "outputId": "853b0466-df9d-46bf-be1a-79a318565a1b"
      },
      "outputs": [],
      "source": [
        "# 2) GPU-build and compile the convolutional neural network (CNN) model - ONLY ONCE\n",
        "K.clear_session()\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "# Allow memory growth on the GPU\n",
        "# physical_devices = tf.config.list_physical_devices('GPU')\n",
        "# for device in physical_devices:\n",
        "#     tf.config.experimental.set_memory_growth(device, True)\n",
        "# strategy = tf.distribute.MirroredStrategy()\n",
        "# with strategy.scope():\n",
        "with tf.device('/GPU:0'):\n",
        "    CNN2 = keras.Sequential([\n",
        "                    # first convolutional layer\n",
        "                    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # second convolutional layer with 64 neurons and w/out shape\n",
        "                    Conv2D(64, (3, 3), activation='relu'),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # third convolutional layer with 64 neurons and w/out shape\n",
        "                    Conv2D(128, (3, 3), activation='relu'),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # # Flatten out the layers\n",
        "                    # Flatten(),\n",
        "                    # Dense layer with 64 neurons and relu activation\n",
        "                    GlobalAveragePooling2D(),\n",
        "                    BatchNormalization(),\n",
        "                    # Dropout layer to prevent overfitting by dropping 50% of neurons\n",
        "                    Dropout(0.4),\n",
        "                    # Output layer with 1000 classes and softmax activation\n",
        "                    Dense(1000, activation='softmax')\n",
        "            ])\n",
        "\n",
        "    # compile model with adam, categorical crossentropy, accuracy, precision, and recall\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    CNN2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy', Precision(), Recall()])\n",
        "\n",
        "# train the model\n",
        "K.clear_session()\n",
        "hist_2 = CNN2.fit(\n",
        "    X_train, Y_hot,\n",
        "    batch_size=8,\n",
        "    epochs=50,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# plot training results\n",
        "plot_training_results(hist_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Early stopping fails to outperform when compared to the previous model. Accuracy 8.9% for a validation accuracy of 1.8%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3) GPU-build and compile the convolutional neural network (CNN) model - ONLY ONCE\n",
        "K.clear_session()\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "# Allow memory growth on the GPU\n",
        "# physical_devices = tf.config.list_physical_devices('GPU')\n",
        "# for device in physical_devices:\n",
        "#     tf.config.experimental.set_memory_growth(device, True)\n",
        "# strategy = tf.distribute.MirroredStrategy()\n",
        "# with strategy.scope():\n",
        "with tf.device('/GPU:0'):\n",
        "    CNN3 = keras.Sequential([\n",
        "                    # 1st convolutional layer\n",
        "                    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # 2nd convolutional layer with 64 neurons and w/out shape\n",
        "                    Conv2D(64, (3, 3), activation='relu'),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # 3rd convolutional layer with 64 neurons and w/out shape\n",
        "                    Conv2D(128, (3, 3), activation='relu'),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # # Flatten out the layers\n",
        "                    # Flatten(),\n",
        "                    # Dense layer with 64 neurons and relu activation\n",
        "                    GlobalAveragePooling2D(),\n",
        "                    BatchNormalization(),\n",
        "                    # Dropout layer to prevent overfitting by dropping 10% of neurons\n",
        "                    Dropout(0.001),\n",
        "                    # Output layer with 1000 classes and softmax activation\n",
        "                    Dense(1000, activation='softmax')\n",
        "            ])\n",
        "\n",
        "    # compile model with adam, categorical crossentropy, accuracy, precision, and recall\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    CNN3.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy', Precision(), Recall()])\n",
        "\n",
        "# train the model\n",
        "K.clear_session()\n",
        "hist_3 = CNN3.fit(\n",
        "    X_train, Y_hot,\n",
        "    batch_size=8,\n",
        "    epochs=100,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# plot training results\n",
        "plot_training_results(hist_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Val_acc seems stuck"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
